ABOUT//

I've ordered tcp streams to build data in the past by concatenating ordered partial results generated from pcap files  which were already subdivided by time.  Distributed; but not as useful or flexible as using Hadoop/Hive.

After searching for a little while I came across a wonderful project 'Hadoop-Pcap' with a nice pcap deserializer.  The project didn't parse seq/ack fields, so I wrote in the support (viva la open source); the rest became pretty straight forward.

(they've already merged the features I added into the main branch if you'd like to use the upstream version)

https://github.com/RIPE-NCC/hadoop-pcap

This version is following streams by calculating relative sequence/acknowlegement numbers and adding them up to produce a 'flow_id' which, of course, increments as information is passed from src->dst and vice versa.  So far, on my small sample sets, this method is working in cases where the start of a stream is clearly delimited.  Once I find an adequate way to create an estimated relative seq/ack for broken streams I'll focus on testing the scripts with more varied data until they break.

TO RUN//

load a pcap file, or the test file, into a directory on your hdfs '/pcap' and alter the file paths in run-prototype.hql.

From there you *should* be able to just run hive -f <path-to-dir>/run-prototype.hql 
The results will end up in a table named apcap_streams.
