add jar /home/hadoop/hive-tcp-stream-prototype/hadoop-pcap-serde-0.2-SNAPSHOT-jar-with-dependencies.jar;
add file /home/hadoop/hive-tcp-stream-prototype/tcp-map.py;
add file /home/hadoop/hive-tcp-stream-prototype/tcp-reduce.py;

--Load packet data into table 'apcap' from hdfs location '/pcap'

create external table apcap (ts bigint,tsmicros bigint,tcp_seq bigint,tcp_ack bigint,tcp_flag_syn string,tcp_flag_ack string,protocol string,src string,src_port int,dst string,dst_port int,len int,ttl int) row format serde 'net.ripe.hadoop.pcap.serde.PcapDeserializer' stored as inputformat 'net.ripe.hadoop.pcap.io.PcapInputFormat' outputformat 'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat' location '/pcap';

--Set up reducing table

create table apcap_streams (ts bigint,tsmicros bigint,tcp_seq bigint,tcp_ack bigint,tcp_flag_syn string,tcp_flag_ack string,ip1 string,port1 int,ip2 string,port2 int);

--Actually order the streams.  Be sure to change the file_path for the scripts.

FROM (
FROM apcap
MAP apcap.ts,apcap.tsmicros,apcap.tcp_seq,apcap.tcp_ack,apcap.src,apcap.src_port,apcap.dst,apcap.dst_port,apcap.tcp_flag_syn,apcap.tcp_flag_ack,apcap.protocol using '/home/hadoop/hive-tcp-stream-prototype/tcp-map.py' as combo,ts,tsmicros,tcp_seq,tcp_ack,tcp_flag_syn,tcp_flag_ack,protocol
CLUSTER BY combo) map_output
INSERT OVERWRITE TABLE apcap_streams
REDUCE map_output.combo,map_output.ts,map_output.tsmicros,map_output.tcp_seq,map_output.tcp_ack,map_output.tcp_flag_syn,map_output.tcp_flag_ack
USING '/home/hadoop/hive-tcp-stream-prototype/tcp-reduce.py'
AS (ts,tsmicros,tcp_seq,tcp_ack,tcp_flag_syn,tcp_flag_ack,ip1,port1,ip2,port2) WHERE protocol="TCP";
